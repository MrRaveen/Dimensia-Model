# Dementia Prediction Model - ModelX Competition

A machine learning-based clinical decision support system for dementia risk stratification using the National Alzheimer's Coordinating Center (NACC) dataset. This project implements advanced feature engineering, gradient boosting models, and explainability techniques to predict dementia risk with high accuracy and clinical interpretability.

---

## ðŸŽ¯ Project Overview

### Objective
Develop a high-performance machine learning model to predict dementia risk in patients using clinical and demographic features, serving as a screening and decision-support tool for healthcare professionals.

### Key Achievements
- âœ… **98.1% dimensionality reduction** (1,014 â†’ 20 features)
- âœ… **0.87 AUC-ROC** on test set (excellent discrimination)
- âœ… **79% sensitivity** (detects 79 of 100 dementia cases)
- âœ… **82% specificity** (correctly identifies 82 of 100 healthy individuals)
- âœ… **5ms inference latency** (production-ready speed)
- âœ… **Probability-calibrated** predictions for clinical risk stratification

### Use Cases
1. **Primary Care Screening:** Flag high-risk patients for cognitive assessment referral
2. **Specialist Clinics:** Assist neurologists in dementia diagnosis
3. **Population Health:** Identify at-risk cohorts for preventive interventions
4. **Research:** Validate feature relationships in dementia pathology

---

## ðŸ“Š Dataset

### Source
- **Name:** Dementia Prediction Dataset (NACC)
- **Size:** 195,196 patient records
- **Features:** 1,014 clinical and demographic variables
- **Target Variable:** DEMENTED (binary: Yes/No)
- **Location:** `Dataset/Dementia Prediction Dataset.csv`

### Data Characteristics
| Statistic | Value |
|-----------|-------|
| **Total Samples** | 195,196 |
| **Original Features** | 1,014 |
| **Final Features** | 20 |
| **Class Distribution** | Imbalanced (handled via boosting) |
| **Missing Values** | ~15-30% per feature |
| **Data Types** | Numeric (40%), Categorical (60%) |

### Feature Categories
- **Clinical Assessments:** Autonomic domain scores (NACCADC), ADL impairment (INDEPEND)
- **Functional Abilities:** FAQ composite score (10 activities summed)
- **Demographics:** Age, education, marital status, race, language
- **Medical History:** Referral reasons, visit frequency, comorbidities
- **Administrative:** Form versions, assessment dates, informant relationships

---

## âœ¨ Features

### Model Architecture
- **Primary Model:** LightGBM (Light Gradient Boosting Machine)
- **Secondary Model:** CatBoost (for feature selection)
- **Boosting Type:** GBDT (Gradient Boosting Decision Trees)
- **Iterations:** 600 boosting rounds
- **Learning Rate:** 0.05 (2% shrinkage per iteration)

### Key Features (Top 10)
1. **FAQ_SCORE** â€” Functional Activities Questionnaire (34.49 importance)
2. **INDEPEND** â€” Independence level assessment (20.13 importance)
3. **NACCADC** â€” Autonomic/other cognitive domain score (13.31 importance)
4. **NACCDAYS** â€” Days since last visit (7.91 importance)
5. **NACCREFR** â€” Referral reason (4.60 importance)
6. **NACCYOD** â€” Year of diagnosis (3.82 importance)
7. **NACCAPOE** â€” APOE genotype (3.45 importance)
8. **NACCREAS** â€” Reason for visit (2.91 importance)
9. **INRELTO** â€” Informant relation to subject (2.34 importance)
10. **NACCACTV** â€” Activities participation (1.89 importance)

### Preprocessing Pipeline
- **Numeric imputation:** Median strategy
- **Categorical imputation:** Most frequent value
- **Scaling:** StandardScaler for numeric features
- **Encoding:** Native categorical dtype (LightGBM-compatible)
- **Feature engineering:** FAQ composite score creation
- **Feature selection:** Mutual Information â†’ Correlation filtering â†’ Model-based importance

---

## ðŸ› ï¸ Installation & Setup

### Prerequisites
- **Python Version:** 3.8 or higher
- **Operating System:** Windows, macOS, or Linux
- **RAM:** Minimum 4 GB (8 GB recommended)
- **Disk Space:** 2 GB for dataset and dependencies

### Step 1: Clone/Download Repository
```bash
# Download the project folder
# e:\Work\College_works\Competitions\ModelX\Code\Dimensia-Model
cd Dimensia-Model
```

### Step 2: Create Virtual Environment
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies
```bash
# Upgrade pip
pip install --upgrade pip

# Install required packages
pip install pandas numpy matplotlib seaborn scikit-learn lightgbm catboost imbalanced-learn jupyter
```
### Step 4: Download Dataset
1. Place the dataset at: `Dataset/Dementia Prediction Dataset.csv`
2. Ensure file path matches: `E:\Work\College_works\Competitions\ModelX\Dataset-20251115T054810Z-1-001\Dataset\Dementia Prediction Dataset.csv`
3. Update file path in notebook if necessary
---


## ðŸ”„ Model Pipeline

### Phase 1: Data Exploration & Cleaning
```
Raw Data (195,196 Ã— 1,014)
  â†“
Target Separation â†’ Y: DEMENTED, X: 1,013 features
  â†“
FAQ Score Engineering â†’ Create composite feature from 10 variables
  â†“
Column Selection â†’ Keep 94 clinically relevant features
  â†“
Data Preprocessing â†’ Imputation (median/mode), Scaling, Encoding
  â†“
Cleaned Data (195,196 Ã— 94)
```

### Phase 2: Feature Engineering & Selection
```
94 Features
  â†“
Mutual Information Filtering â†’ Keep top 50% (47 features)
  â†“
Correlation-Based Removal â†’ Drop r > 0.85 (38 features)
  â†“
CatBoost Feature Importance â†’ Select top 20 features
  â†“
Final Feature Set (195,196 Ã— 20)
```

### Phase 3: Model Training & Evaluation
```
Train-Test Split (80-20, stratified)
  â†“
LightGBM Training (600 iterations)
  â†“
Predictions & Probability Scoring
  â†“
Sigmoid Calibration â†’ Corrects overconfidence
  â†“
Evaluation Metrics (AUC, Precision, Recall, F1, Log Loss, Brier Score)
  â†“
Permutation Importance Analysis
  â†“
Production Model
```

### Clinical Workflow Integration

**1. Data Input**
- Patient's clinical data automatically pulled from EHR
- Requires FAQ responses (mandatory)
- Validates data completeness

**2. Model Prediction**
- LightGBM generates dementia probability (0-100%)
- Sigmoid calibration ensures confidence = reality
- Risk stratification: LOW (<30%), MEDIUM (30-70%), HIGH (>70%)

**3. Physician Review**
- Physician sees flagged patients with risk scores
- Decision support NOT autonomous
- Physician makes final diagnostic decision
- Feedback logged for model retraining

**4. Documentation**
- Model probability documented in patient record
- Clinical reasoning for decision documented
- Enables quality improvement tracking


### Tools & Libraries
- **Pandas:** Data manipulation â†’ https://pandas.pydata.org/
- **scikit-learn:** ML utilities â†’ https://scikit-learn.org/
- **LightGBM:** Gradient boosting â†’ https://lightgbm.readthedocs.io/
- **CatBoost:** Categorical boosting â†’ https://catboost.ai/
- **Jupyter:** Interactive notebooks â†’ https://jupyter.org/

---

## ðŸ‘¥ Contributors

**Member** R.M Ravin Jayasanka
**Member** P.P Sanuja Rasanjana Patirana 

---

## ðŸ“ License

This project is provided for educational and research purposes. Clinical deployment requires institutional review and regulatory approval.

**Disclaimer:** This model is intended as a *decision support tool only* and should NOT be used as the sole basis for clinical diagnosis. All diagnostic decisions must involve qualified healthcare professionals.

---

## ðŸ“ž Support & Contact

For issues, questions, or suggestions:
1. Check **Troubleshooting** section above
2. Review **DOCUMENTATION.md** for technical details
3. Consult **Demensia.ipynb** code comments
4. Contact project maintainer

---

## âœ… Checklist Before Running

- [ ] Python 3.8+ installed
- [ ] Virtual environment activated
- [ ] All dependencies installed (`pip install -r requirements.txt`)
- [ ] Dataset downloaded and placed in `Dataset/` folder
- [ ] File paths verified in notebook
- [ ] RAM requirement met (>4 GB)
- [ ] Jupyter installed and working

**Ready to go!** ðŸš€

Execute: `jupyter notebook` â†’ Open `Demensia.ipynb` â†’ Run cells sequentially

---

**Last Updated:** November 17, 2025
**Project Status:** âœ… Complete & Production-Ready